# Analyze Benchmark

ベンチマーク結果の JSON を読み込み、LLM の行動品質を多角的に分析して具体的な改善アクションを提案する。

## 引数の解析

ユーザーの入力から結果ファイルのパスを抽出する:

- `/analyze-benchmark` → `benchmark_results/` 内の最新ファイルを自動検出
- `/analyze-benchmark benchmark_results/result_20260223.json` → 指定ファイル

## ワークフロー

### Step 1: 結果ファイルの読み込み

指定された JSON ファイル、または `benchmark_results/` 内の最新ファイルを読み込む。

### Step 2: 勝率分析

- 陣営別勝率の評価
- Random との差分（比較データがある場合）
- LLM がどの程度「賢く」プレイできているかの評価

### Step 3: ゲーム展開分析

- ターン数の分布
- 人狼の発見されやすさ（何ターン目に処刑されるか）
- 各ゲームの勝敗パターン

### Step 4: API パフォーマンス分析

- アクション種別ごとのレイテンシ（結果 JSON から読み取れる場合）
- 総 API 呼び出し回数
- 推定コスト（モデル名からトークン単価を概算）

### Step 5: 改善提案

分析結果に基づき、以下の観点で改善を提案する:

- **プロンプト改善**: 勝率が低い場合のプロンプト修正方向性
- **パラメータ調整**: temperature の変更提案
- **新機能提案**: 必要に応じて `/create-issue` で Issue 化

### Step 6: レポート出力

分析結果をマークダウン形式でユーザーに報告する。
